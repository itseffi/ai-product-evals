# AI Product Evals - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM PROVIDERS (configure at least one)
# =============================================================================

# Ollama - Local/Open Source (recommended for free usage)
# Install: https://ollama.ai
OLLAMA_BASE_URL=http://localhost:11434

# OpenRouter - Access many models through one API
# Get key: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# OpenAI
# Get key: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic
# Get key: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Google Gemini
# Get key: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=

# =============================================================================
# EVAL SETTINGS
# =============================================================================

# Default provider to use when not specified in eval config
# Options: ollama, openrouter, openai, anthropic, google
DEFAULT_PROVIDER=ollama

# Judge provider/model for LLM-as-judge evaluations
JUDGE_PROVIDER=ollama
JUDGE_MODEL=qwen3:8b

# Request timeout in milliseconds
EVAL_TIMEOUT_MS=180000

# =============================================================================
# PERFORMANCE
# =============================================================================

# Maximum concurrent requests (for --parallel mode)
PARALLEL_LIMIT=3

# Retry settings
MAX_RETRIES=2
RETRY_DELAY_MS=1000

# =============================================================================
# CACHING
# =============================================================================

# Enable response caching (set to false to disable)
USE_CACHE=true

# Cache TTL in milliseconds (default: 24 hours)
CACHE_TTL_MS=86400000

# =============================================================================
# DEBUG
# =============================================================================

# Enable debug logging
DEBUG=false
